{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08979a1d",
   "metadata": {},
   "source": [
    "# Εργασία Ανάκτησης Πληροφορίας\n",
    "## Δημιουργία μηχανής αναζήτησης \n",
    "### Βήμα 1. Συλλογή δεδομένων:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d665cda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Συλλέχθηκαν 1000 άρθρα.\n",
      "{\n",
      "    \"ID\": 3,\n",
      "    \"Title\": \"Meir Shalev\",\n",
      "    \"Body\": \"Israeli writer (1948–2023)\\n\\n\\nMeir ShalevShalev in 2015Bornמאיר שלו(1948-07-29)29 July 1948Nahalal, IsraelDied11 April 2023(2023-04-11) (aged 74)Alonei Abba, IsraelLanguageHebrewNationalityIsraeliNotable awardsBernstein Prize,Brenner Prize\\nMeir Shalev and the theater performance team at the end of the play \\\"Uncle Aaron and his Rain\\\" which won the first prize at the Haifa International Children's Theater Festival in 2017\\nThe grave of Meir Shalev is covered with flowers after the funeral, April 13, 2023\\nMeir Shalev (Hebrew: מאיר שלו; 29 July 1948 – 11 April 2023) was an Israeli writer and newspaper columnist[1] for the daily Yedioth Ahronoth. Shalev's books have been translated into 26 languages.[2]\\n\\n\\nBiography[edit]\\nShalev was born in Nahalal, Israel. Later he lived in Jerusalem and at Ginosar with his family. He is the son of the Jerusalem poet Yitzhak Shalev. His cousin Zeruya Shalev is also a writer.\\nShalev was drafted into the IDF in 1966, and did his military service in the Golani Brigade. He served as a soldier, a squad leader  in the brigade's reconnaissance company. Shalev fought in The Six Day War,[3] and a few months after the war was injured in a friendly fire incident.\\nShalev began his career by presenting ironic features on television and radio. He also moderated the program Erev Shabbat (\\\"Friday night\\\") on Israel channel one. His first novel, The Blue Mountain, was published in 1988.\\nShalev also wrote non-fiction, children's books, and a weekly column in the weekend edition of Yediot Ahronot.\\nShalev lived in the Jezreel Valley until his death on 11 April 2023, following a prolonged battle with cancer. He was 74.[2] Upon news of Shalev's death, Israeli President Isaac Herzog expressed condolences: \\\"Israel has lost one of its greatest storytellers, he made us love the Hebrew language, the Hebrew Bible, and ourselves, the Jewish People\\\".[4]\\n\\nViews and opinions[edit]\\nAccording to a January 2009 interview, Shalev identified with the Israeli left and believed that the conflict with the Palestinians could be resolved by establishing two states for two peoples. However, he expressed disappointment towards the extremism in the Palestinian camp, saying: \\\"Radical Palestinians still say that the only solution would be for all Jews to pack their bags and return to where their grandparents came from. When there are no more Jews left in the Middle East, then the problem is solved, according to their logic. As long as they continue to think that way, there will be no peace. We are here and we are going to stay. Only after that fact is generally accepted can progress be made.\\\"[5]\\n\\nAwards and recognition[edit]\\nBernstein Prize (original Hebrew novel category) (1989)[6]\\nJuliet Club Prize (1999)[6]\\nChiavari Prize (1999)[6]\\nBrenner Prize (Israel) for A Pigeon and a Boy (2006)\\nNational Jewish Book Award for A Pigeon and a Boy (2007)[6][7]\\nPorta Siberia Prize (2009)[6]\\nPratt Award for Environmental Journalism (2009)[6]\\nNeuman Prize (2011)[6]\\nChevalier of the Ordre des Arts et des Lettres, along with Michal Govrin, in 2018[8]\\nPublished works[edit]\\nFiction[edit]\\n1988 The Blue Mountain ISBN 0-06-016691-6 (1988, originally published in Hebrew as Roman Rusi) English translation in 1991 by Hillel Halkin. Reprinted, 2010\\n1991 Esau ISBN 0-06-019040-X\\n1994 As a Few Days, also called The Four Meals or The Loves of Judith ISBN 1-84195-114-5[9]\\n1998 His House in the Desert (or \\\"Alone in the Desert\\\")\\n2002 Fontanelle ISBN 3-257-23554-2\\n2006 A Pigeon and A Boy (originally published in Hebrew as Yona v'naar by Am Oved Publishers, Tel Aviv), translated by Evan Fallenberg, Random House, New York, ISBN 978-0-8052-4251-5\\n2013 Two She-Bears[2]\\n2022 'Al Tesaper le-Akhicha (Hebrew: \\\"Don't Tell Your Brother\\\")\\nNon-fiction[edit]\\n1985 Bible Now, a book containing interpretations of Hebrew Bible stories from his personal point of view, which first appeared in the newspaper Haaretz.\\nElements of Conjuration\\n1995 Mainly About Love\\n1998 My Jerusalem\\n2008 In the Beginning: Firsts in the Bible\\n2011 Beginnings:  Reflections on the Bible's Intriguing Firsts ISBN 0-307-71718-6  (Nonfiction)\\n2011 My Russian Grandmother and Her American Vacuum Cleaner ISBN 0-8052-4287-2 [10]\\n2017 My Wild Garden\\nChildren's books[edit]\\n1982 Michael and the Monster of Jerusalem ISBN 965-382-001-X\\n1987 Zohar's Dimples\\n1988 My Father Always Embarrasses Me\\n1990 Nehama the Louse (also published as A Louse Named Thelma)\\n1993 How the Neanderthal Inadvertently Invented Kebab\\n1994 A flood, a snake and two arks\\n2021 “A Snake, a Flood, a Hidden Baby” (Eng, Kalaniot Books, USA)\\n1995 The Tractor in the Sandbox\\n2000 Aunt Michal\\n2004 A Lion at Night\\n2004 Roni and Nomi and the Bear Yaacov\\n2007 Uncle Aaron and his Rain\\nReferences[edit]\\n\\n\\n^ \\\"Meir Shalev\\\". New York Journal of Books. Retrieved 9 July 2016.\\n\\n^ a b c Meir Shalev publishes new novel and talks violence, the New Man and why he avoids politics\\n\\n^ Meir Shalev, What happened to our army?, Ynetnews, 4 March 2008.\\n\\n^ Dennis Bihler, Israeli famed author Meir Shalev dies at 74, Ynetnews, 11 April 2023.\\n\\n^ Israeli author Meir Shalev: Even the left was in favor of striking Hamas, Der Spiegel, 2 January 2009, retrieved 15 April 2020\\n\\n^ a b c d e f g \\\"Meir Shalev\\\". Israeli Institute for Hebrew Literature. Retrieved 11 April 2023.\\n\\n^ \\\"Past Winners - Fiction\\\". Jewish Book Council. Retrieved 20 January 2020.\\n\\n^ \\\"Décoration de Roselyne Dery et de Meir Shalev\\\". La France en Israël - Ambassade de France à Tel Aviv (in French). 4 October 2018. Retrieved 29 January 2018.[permanent dead link]\\n\\n^ \\\"Three men and a baby\\\". The Guardian. 16 April 2000. Archived from the original on 13 April 2023.\\n\\n^ Meir Shalev's My Russian Grandmother and Her American Vacuum Cleaner\\n\\n\\nMeir Shalev in duet with jazz guitarist Dekel Bor\\n\\nExternal links[edit]\\n\\\"You were caught with your trousers down in a war of your own making\\\", speech at Tel Aviv mass rally, May 2007\\nAuthority control databases International\\nFAST\\nISNI\\nVIAF\\nWorldCat\\nNational\\nNorway\\nChile\\nSpain\\nFrance\\nBnF data\\nCatalonia\\nGermany\\nItaly\\nIsrael\\nBelgium\\nUnited States\\nLatvia\\nJapan\\nCzech Republic\\nAustralia\\nGreece\\nKorea\\nNetherlands\\nPoland\\nPortugal\\nAcademics\\nCiNii\\nArtists\\nMusicBrainz\\nPeople\\nDeutsche Biographie\\nTrove\\nOther\\nSNAC\\nIdRef\",\n",
      "    \"URL\": \"https://en.wikipedia.org/wiki/Meir_Shalev\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Διαβάζουμε το αρχείο JSON\n",
    "with open('articles.json', 'r', encoding='utf-8') as file:\n",
    "    articles = json.load(file)\n",
    "\n",
    "# Εξάγουμε τα δεδομένα των άρθρων\n",
    "documents = []\n",
    "for article in articles:\n",
    "    doc = {\n",
    "        'ID': article.get('ID'),\n",
    "        'Title': article.get('Title'),\n",
    "        'Body': article.get('Body', ''),\n",
    "        'URL': article.get('URL'),\n",
    "    }\n",
    "    documents.append(doc)\n",
    "\n",
    "# Εμφανίζουμε τον αριθμό των εγγράφων που συλλέχθηκαν\n",
    "print(f\"Συλλέχθηκαν {len(documents)} άρθρα.\")\n",
    "\n",
    "# Παράδειγμα εμφάνισης ενός εγγράφου\n",
    "print(json.dumps(documents[0], indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa5c300",
   "metadata": {},
   "source": [
    "### Βήμα 2. Προεπεξεργασία κειμένου (Text Processing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a51d51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\agram\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\agram\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Η προεπεξεργασία ολοκληρώθηκε και τα δεδομένα αποθηκεύτηκαν στο 'processed_articles.json'.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "# Κατεβάζουμε τα απαραίτητα δεδομένα για το nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Stop words και stemming\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Συνάρτηση για καθαρισμό κειμένου\n",
    "def preprocess_text(text):\n",
    "    # Αφαίρεση ειδικών χαρακτήρων\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Μετατροπή σε πεζά γράμματα\n",
    "    text = text.lower()\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Αφαίρεση stop-words και stemming\n",
    "    filtered_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Προεπεξεργασία όλων των άρθρων\n",
    "for doc in documents:\n",
    "    doc['Processed_Body'] = preprocess_text(doc['Body'])\n",
    "\n",
    "# Αποθήκευση προεπεξεργασμένων δεδομένων\n",
    "with open('processed_articles.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(documents, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"Η προεπεξεργασία ολοκληρώθηκε και τα δεδομένα αποθηκεύτηκαν στο 'processed_articles.json'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f9410",
   "metadata": {},
   "source": [
    "### Βήμα 3. Ευρετήριο (Indexing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3226239a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Το ανεστραμμένο ευρετήριο δημιουργήθηκε και αποθηκεύτηκε στο 'inverted_index.json'.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Δημιουργία ανεστραμμένου ευρετηρίου\n",
    "def create_inverted_index(documents):\n",
    "    inverted_index = defaultdict(list)  # Λεξικό για το ευρετήριο\n",
    "    for doc in documents:\n",
    "        doc_id = doc['ID']\n",
    "        words = doc['Processed_Body'].split()\n",
    "        word_counts = defaultdict(int)  # Μετρητής λέξεων στο έγγραφο\n",
    "        for word in words:\n",
    "            word_counts[word] += 1\n",
    "        \n",
    "        # Ενημέρωση του ανεστραμμένου ευρετηρίου\n",
    "        for word, count in word_counts.items():\n",
    "            inverted_index[word].append({'doc_id': doc_id, 'frequency': count})\n",
    "    \n",
    "    return inverted_index\n",
    "\n",
    "# Δημιουργούμε το ευρετήριο\n",
    "inverted_index = create_inverted_index(documents)\n",
    "\n",
    "# Αποθήκευση του ευρετηρίου σε αρχείο\n",
    "with open('inverted_index.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(inverted_index, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"Το ανεστραμμένο ευρετήριο δημιουργήθηκε και αποθηκεύτηκε στο 'inverted_index.json'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724b8e3f",
   "metadata": {},
   "source": [
    "### Βήμα 4. Μηχανή αναζήτησης (Search Engine):\n",
    "#### α) Επεξεργασία ερωτήματος (Query Processing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20dfab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Εισάγετε το ερώτημά σας (ή γράψτε 'exit' για τερματισμό): exit\n",
      "Τερματισμός αναζήτησης.\n"
     ]
    }
   ],
   "source": [
    "# Συνάρτηση για την επεξεργασία του ερωτήματος\n",
    "def process_query(query):\n",
    "    query = re.sub(r'[^a-zA-Z\\s]', '', query).lower()\n",
    "    tokens = word_tokenize(query)\n",
    "    filtered_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "# Συνάρτηση για την εκτέλεση αναζήτησης\n",
    "def search(query, inverted_index):\n",
    "    if \"AND\" in query:\n",
    "        # Boolean: AND\n",
    "        terms = query.split(\"AND\")\n",
    "        if len(terms) == 2:\n",
    "            term1 = process_query(terms[0].strip())[0]\n",
    "            term2 = process_query(terms[1].strip())[0]\n",
    "\n",
    "            docs1 = {doc['doc_id'] for doc in inverted_index.get(term1, [])}\n",
    "            docs2 = {doc['doc_id'] for doc in inverted_index.get(term2, [])}\n",
    "            \n",
    "            results = list(docs1 & docs2)\n",
    "            return results\n",
    "        else:\n",
    "            print(\"Σφάλμα στο ερώτημα. Χρησιμοποιήστε σωστή σύνταξη: text1 AND text2.\")\n",
    "            return []\n",
    "\n",
    "    elif \"OR\" in query:\n",
    "        # Boolean: OR\n",
    "        terms = query.split(\"OR\")\n",
    "        results = set()\n",
    "        for term in terms:\n",
    "            term = process_query(term.strip())[0]\n",
    "            results.update({doc['doc_id'] for doc in inverted_index.get(term, [])})\n",
    "        return list(results)\n",
    "\n",
    "    elif \"NOT\" in query:\n",
    "        # Boolean: NOT\n",
    "        term = process_query(query.split(\"NOT\")[1].strip())[0]\n",
    "        all_docs = {doc['ID'] for doc in documents}\n",
    "        exclude_docs = {doc['doc_id'] for doc in inverted_index.get(term, [])}\n",
    "        results = list(all_docs - exclude_docs)\n",
    "        return results\n",
    "\n",
    "    else:\n",
    "        # Μοναδικός όρος αναζήτησης\n",
    "        term = process_query(query.strip())[0]\n",
    "        results = [doc['doc_id'] for doc in inverted_index.get(term, [])]\n",
    "        return results\n",
    "\n",
    "# Διαρκής αναζήτηση μέχρι ο χρήστης να σταματήσει\n",
    "while True:\n",
    "    query = input(\"Εισάγετε το ερώτημά σας (ή γράψτε 'exit' για τερματισμό): \").strip()\n",
    "    if query.lower() == 'exit':\n",
    "        print(\"Τερματισμός αναζήτησης.\")\n",
    "        break\n",
    "\n",
    "    results = search(query, inverted_index)\n",
    "\n",
    "    # Προβολή αποτελεσμάτων\n",
    "    if results:\n",
    "        print(f\"Βρέθηκαν {len(results)} σχετικά έγγραφα:\\n\")\n",
    "        for doc_id in results:\n",
    "            doc = next((d for d in documents if d['ID'] == doc_id), None)\n",
    "            print(f\"ID: {doc['ID']}, Τίτλος: {doc['Title']}, URL: {doc['URL']}\")\n",
    "    else:\n",
    "        print(\"Δε βρέθηκαν σχετικά έγγραφα.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53801c00",
   "metadata": {},
   "source": [
    "#### β) Κατάταξη αποτελεσμάτων (Ranking):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5a1e089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\agram\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: rank-bm25 in c:\\users\\agram\\anaconda3\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\agram\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\agram\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\agram\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\agram\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Εισάγετε το ερώτημά σας (ή γράψτε 'exit' για τερματισμό): open\n",
      "Επιλέξτε αλγόριθμο (TF-IDF, BM25, VSM): TF-IDF\n",
      "Βρέθηκαν 175 σχετικά έγγραφα με τον αλγόριθμο TF-IDF:\n",
      "\n",
      "1. ID: 138, Τίτλος: Andrew Campbell (golfer), Σκορ: 0.2732, URL: https://en.wikipedia.org/wiki/Andrew_Campbell_(golfer)\n",
      "2. ID: 281, Τίτλος: 2024 Córdoba Open, Σκορ: 0.1364, URL: https://en.wikipedia.org/wiki/2024_C%C3%B3rdoba_Open\n",
      "3. ID: 369, Τίτλος: Pakistan Open, Σκορ: 0.1085, URL: https://en.wikipedia.org/wiki/Pakistan_Open\n",
      "4. ID: 656, Τίτλος: Piano Trio No. 43 (Haydn), Σκορ: 0.0747, URL: https://en.wikipedia.org/wiki/Piano_Trio_No._43_(Haydn)\n",
      "5. ID: 607, Τίτλος: 2004 Wimbledon Championships – Mixed doubles, Σκορ: 0.0733, URL: https://en.wikipedia.org/wiki/2004_Wimbledon_Championships_%E2%80%93_Mixed_doubles\n",
      "6. ID: 661, Τίτλος: Costa Rica at the 2013 World Aquatics Championships, Σκορ: 0.0635, URL: https://en.wikipedia.org/wiki/Costa_Rica_at_the_2013_World_Aquatics_Championships\n",
      "7. ID: 565, Τίτλος: 2011 Australian Open – Wheelchair men's doubles, Σκορ: 0.0624, URL: https://en.wikipedia.org/wiki/2011_Australian_Open_%E2%80%93_Wheelchair_men's_doubles\n",
      "8. ID: 688, Τίτλος: 2016 Milo Open Cali – Doubles, Σκορ: 0.0573, URL: https://en.wikipedia.org/wiki/2016_Milo_Open_Cali_%E2%80%93_Doubles\n",
      "9. ID: 554, Τίτλος: Pseudosoloe, Σκορ: 0.0547, URL: https://en.wikipedia.org/wiki/Pseudosoloe\n",
      "10. ID: 95, Τίτλος: Elora Rocks, Σκορ: 0.0502, URL: https://en.wikipedia.org/wiki/Elora_Rocks\n",
      "Εισάγετε το ερώτημά σας (ή γράψτε 'exit' για τερματισμό): born\n",
      "Επιλέξτε αλγόριθμο (TF-IDF, BM25, VSM): vsm\n",
      "Βρέθηκαν 269 σχετικά έγγραφα με τον αλγόριθμο VSM:\n",
      "\n",
      "1. ID: 434, Τίτλος: Yamanaka, Σκορ: 0.1634, URL: https://en.wikipedia.org/wiki/Yamanaka\n",
      "2. ID: 501, Τίτλος: De Lange, Σκορ: 0.1463, URL: https://en.wikipedia.org/wiki/De_Lange\n",
      "3. ID: 475, Τίτλος: 1874 in art, Σκορ: 0.1382, URL: https://en.wikipedia.org/wiki/1874_in_art\n",
      "4. ID: 437, Τίτλος: Gary Taylor (baseball), Σκορ: 0.1332, URL: https://en.wikipedia.org/wiki/Gary_Taylor_(baseball)\n",
      "5. ID: 900, Τίτλος: Boyd Jones, Σκορ: 0.1171, URL: https://en.wikipedia.org/wiki/Boyd_Jones\n",
      "6. ID: 313, Τίτλος: Halimi, Σκορ: 0.1108, URL: https://en.wikipedia.org/wiki/Halimi\n",
      "7. ID: 52, Τίτλος: Harry Theofiledes, Σκορ: 0.1067, URL: https://en.wikipedia.org/wiki/Harry_Theofiledes\n",
      "8. ID: 701, Τίτλος: Labrooy, Σκορ: 0.1033, URL: https://en.wikipedia.org/wiki/Labrooy\n",
      "9. ID: 282, Τίτλος: Éric Guyot, Σκορ: 0.0963, URL: https://en.wikipedia.org/wiki/%C3%89ric_Guyot\n",
      "10. ID: 561, Τίτλος: Randy Kirk, Σκορ: 0.0960, URL: https://en.wikipedia.org/wiki/Randy_Kirk\n",
      "Εισάγετε το ερώτημά σας (ή γράψτε 'exit' για τερματισμό): Israeli writer\n",
      "Επιλέξτε αλγόριθμο (TF-IDF, BM25, VSM): TF-IDF\n",
      "Βρέθηκαν 54 σχετικά έγγραφα με τον αλγόριθμο TF-IDF:\n",
      "\n",
      "1. ID: 831, Τίτλος: Rescue of Ori Megidish, Σκορ: 0.3900, URL: https://en.wikipedia.org/wiki/Rescue_of_Ori_Megidish\n",
      "2. ID: 202, Τίτλος: Ephraim (given name), Σκορ: 0.2411, URL: https://en.wikipedia.org/wiki/Ephraim_(given_name)\n",
      "3. ID: 3, Τίτλος: Meir Shalev, Σκορ: 0.1678, URL: https://en.wikipedia.org/wiki/Meir_Shalev\n",
      "4. ID: 533, Τίτλος: North Yemen at the 1988 Summer Olympics, Σκορ: 0.0809, URL: https://en.wikipedia.org/wiki/North_Yemen_at_the_1988_Summer_Olympics\n",
      "5. ID: 271, Τίτλος: Ryōzō Nagashima, Σκορ: 0.0793, URL: https://en.wikipedia.org/wiki/Ry%C5%8Dz%C5%8D_Nagashima\n",
      "6. ID: 792, Τίτλος: Mario Bellatin, Σκορ: 0.0725, URL: https://en.wikipedia.org/wiki/Mario_Bellatin\n",
      "7. ID: 929, Τίτλος: Saifuddin Jalal, Σκορ: 0.0673, URL: https://en.wikipedia.org/wiki/Saifuddin_Jalal\n",
      "8. ID: 798, Τίτλος: Ana María Simo, Σκορ: 0.0600, URL: https://en.wikipedia.org/wiki/Ana_Mar%C3%ADa_Simo\n",
      "9. ID: 172, Τίτλος: Screenplay, Σκορ: 0.0591, URL: https://en.wikipedia.org/wiki/Screenplay\n",
      "10. ID: 356, Τίτλος: Colin Jackson (politician), Σκορ: 0.0589, URL: https://en.wikipedia.org/wiki/Colin_Jackson_(politician)\n",
      "Εισάγετε το ερώτημά σας (ή γράψτε 'exit' για τερματισμό): exit\n",
      "Τερματισμός αναζήτησης.\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn rank-bm25\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "\n",
    "# Προετοιμασία δεδομένων για διαφορετικούς αλγορίθμους\n",
    "corpus = [doc['Processed_Body'] for doc in documents]\n",
    "\n",
    "# 1. TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# 2. BM25\n",
    "bm25 = BM25Okapi([doc.split() for doc in corpus])\n",
    "\n",
    "# Υπολογισμός κατάταξης με διαφορετικούς αλγορίθμους\n",
    "def rank_results(query, algorithm=\"TF-IDF\"):\n",
    "    query_processed = ' '.join(process_query(query))\n",
    "    \n",
    "    if algorithm == \"TF-IDF\":\n",
    "        # Υπολογισμός σχετικότητας με βάση το TF-IDF\n",
    "        query_vector = tfidf_vectorizer.transform([query_processed])\n",
    "        scores = np.dot(tfidf_matrix, query_vector.T).toarray().flatten()\n",
    "        ranked_indices = np.argsort(-scores)\n",
    "    \n",
    "    elif algorithm == \"BM25\":\n",
    "        # Υπολογισμός σχετικότητας με βάση το BM25\n",
    "        scores = bm25.get_scores(query_processed.split())\n",
    "        ranked_indices = np.argsort(-scores)\n",
    "    \n",
    "    elif algorithm == \"VSM\":\n",
    "        # Χρήση TF-IDF ως βάση για VSM\n",
    "        query_vector = tfidf_vectorizer.transform([query_processed])\n",
    "        scores = np.dot(tfidf_matrix, query_vector.T).toarray().flatten()\n",
    "        normalized_scores = scores / np.linalg.norm(scores)\n",
    "        ranked_indices = np.argsort(-normalized_scores)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Μη έγκυρος αλγόριθμος. Επιλέξτε 'TF-IDF', 'BM25' ή 'VSM'.\")\n",
    "    \n",
    "    # Επιστροφή ταξινομημένων αποτελεσμάτων\n",
    "    return [(documents[idx]['ID'], scores[idx]) for idx in ranked_indices if scores[idx] > 0]\n",
    "\n",
    "# Διαδραστική αναζήτηση με επιλογή αλγορίθμου\n",
    "while True:\n",
    "    query = input(\"Εισάγετε το ερώτημά σας (ή γράψτε 'exit' για τερματισμό): \").strip()\n",
    "    if query.lower() == 'exit':\n",
    "        print(\"Τερματισμός αναζήτησης.\")\n",
    "        break\n",
    "    \n",
    "    algorithm = input(\"Επιλέξτε αλγόριθμο (TF-IDF, BM25, VSM): \").strip().upper()\n",
    "    try:\n",
    "        ranked_results = rank_results(query, algorithm)\n",
    "        if ranked_results:\n",
    "            print(f\"Βρέθηκαν {len(ranked_results)} σχετικά έγγραφα με τον αλγόριθμο {algorithm}:\\n\")\n",
    "            for rank, (doc_id, score) in enumerate(ranked_results[:10], start=1):\n",
    "                doc = next((d for d in documents if d['ID'] == doc_id), None)\n",
    "                print(f\"{rank}. ID: {doc['ID']}, Τίτλος: {doc['Title']}, Σκορ: {score:.4f}, URL: {doc['URL']}\")\n",
    "        else:\n",
    "            print(\"Δε βρέθηκαν σχετικά έγγραφα.\")\n",
    "    except ValueError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fc461",
   "metadata": {},
   "source": [
    "### Βήμα 5. Αξιολόγηση συστήματος: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5955adfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Αποτελέσματα για τον αλγόριθμο TF-IDF:\n",
      "- Μέση Ακρίβεια (Precision): 0.0120\n",
      "- Μέση Ανάκληση (Recall): 1.0000\n",
      "- Μέσο F1-Score: 0.0236\n",
      "- Μέση Ακρίβεια (MAP): 0.4811\n",
      "Αποτελέσματα για τον αλγόριθμο BM25:\n",
      "- Μέση Ακρίβεια (Precision): 0.0120\n",
      "- Μέση Ανάκληση (Recall): 1.0000\n",
      "- Μέσο F1-Score: 0.0236\n",
      "- Μέση Ακρίβεια (MAP): 0.7500\n",
      "Αποτελέσματα για τον αλγόριθμο VSM:\n",
      "- Μέση Ακρίβεια (Precision): 0.0120\n",
      "- Μέση Ανάκληση (Recall): 1.0000\n",
      "- Μέσο F1-Score: 0.0236\n",
      "- Μέση Ακρίβεια (MAP): 0.4811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Παράδειγμα δοκιμαστικών ερωτημάτων και αναμενόμενων απαντήσεων\n",
    "test_queries = [\n",
    "    {\"query\": \"Israeli writer\", \"relevant_docs\": [3]},\n",
    "    {\"query\": \"animal actors\", \"relevant_docs\": [1]},\n",
    "    {\"query\": \"US Army general\", \"relevant_docs\": [10]},\n",
    "    {\"query\": \"Punjabi culture\", \"relevant_docs\": [4]},\n",
    "]\n",
    "\n",
    "# Συνάρτηση για αξιολόγηση\n",
    "def evaluate_search_engine(algorithm=\"TF-IDF\"):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    average_precisions = []\n",
    "    \n",
    "    for test in test_queries:\n",
    "        query = test['query']\n",
    "        relevant_docs = set(test['relevant_docs'])\n",
    "\n",
    "        # Λήψη αποτελεσμάτων με κατάταξη\n",
    "        ranked_results = rank_results(query, algorithm)\n",
    "        retrieved_docs = set(doc_id for doc_id, _ in ranked_results)\n",
    "\n",
    "        # Υπολογισμός Precision, Recall, F1\n",
    "        tp = len(retrieved_docs & relevant_docs)  # True Positives\n",
    "        fp = len(retrieved_docs - relevant_docs)  # False Positives\n",
    "        fn = len(relevant_docs - retrieved_docs)  # False Negatives\n",
    "\n",
    "        precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "        recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # Υπολογισμός Average Precision (AP)\n",
    "        average_precision = 0\n",
    "        for k, (doc_id, _) in enumerate(ranked_results):\n",
    "            if doc_id in relevant_docs:\n",
    "                precision_at_k = len(relevant_docs & set([doc_id for doc_id, _ in ranked_results[:k+1]])) / (k + 1)\n",
    "                average_precision += precision_at_k\n",
    "        average_precision /= len(relevant_docs) if relevant_docs else 1\n",
    "        average_precisions.append(average_precision)\n",
    "\n",
    "    # Υπολογισμός μέσων τιμών\n",
    "    mean_precision = sum(precisions) / len(precisions)\n",
    "    mean_recall = sum(recalls) / len(recalls)\n",
    "    mean_f1 = sum(f1_scores) / len(f1_scores)\n",
    "    mean_ap = sum(average_precisions) / len(average_precisions)\n",
    "\n",
    "    print(f\"Αποτελέσματα για τον αλγόριθμο {algorithm}:\")\n",
    "    print(f\"- Μέση Ακρίβεια (Precision): {mean_precision:.4f}\")\n",
    "    print(f\"- Μέση Ανάκληση (Recall): {mean_recall:.4f}\")\n",
    "    print(f\"- Μέσο F1-Score: {mean_f1:.4f}\")\n",
    "    print(f\"- Μέση Ακρίβεια (MAP): {mean_ap:.4f}\")\n",
    "\n",
    "# Εκτέλεση αξιολόγησης για όλους τους αλγορίθμους\n",
    "for algo in [\"TF-IDF\", \"BM25\", \"VSM\"]:\n",
    "    evaluate_search_engine(algo)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
